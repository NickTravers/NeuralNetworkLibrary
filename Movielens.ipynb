{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Movielens is a dataset of (user,movie,rating) triples. Given training data of such triples, \n",
    "we want to predict ratings for unseen (user,movie) pairs. All ratings are between 0.5 and 5.0.\n",
    "\n",
    "\n",
    "The lesson 5 fastai notebook trains a collaborative filtering model on the movielens data in \"ratings.csv\", by choosing a random subset of points to use for validation. A Mean-Squared-Error validation loss of 0.765 is obtained in that notebook, which is a bit better than the best published result for movielens at the time.\n",
    "\n",
    "In this notebook I also train on the movielens dataset in \"ratings.csv\", with a random subset of points chosen for validation. I train in 2 ways:\n",
    "\n",
    "1. Using a collaborative filtering model from my file CollaborativeFiltering.py \n",
    "2. Using a general structured data model from my file StructuredData.py\n",
    "\n",
    "(Note: The collaborative filtering problem is a specific case of the structured data problem with exactly 2 categorical input variables and 1 continuous output variable.)\n",
    "\n",
    "Performance with my collaborative filtering model is a bit better than when using my general strucutured data model, and comporable to the result in the fastai lesson 5 notebook. However, I did not play around too much too optimize parameters in the general structured data model, and there are many more of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# My Imports\n",
    "from General import *\n",
    "from CollaborativeFiltering import *\n",
    "from StructuredData import *\n",
    "\n",
    "# Standard Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Torch Imports\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "PATH = 'data/movielens/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Method 1 - Train Using a Collaborative Filtering Model from CollaborativeFiltering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# data object\n",
    "filename = PATH + 'ratings.csv'\n",
    "data = CollabFilterDataObj.from_csv(filename,'userId','movieId','rating',bs=128)\n",
    "\n",
    "# pytorch model\n",
    "model = CollabFilterNet.from_dataobj(data, emb_dim=50)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# learner \n",
    "learner = Learner(PATH, data, model, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   train_loss  val_loss    \n",
      "\n",
      "0       0.89780     0.97462       epoch run time: 0 min, 4.14 sec\n",
      "1       0.47825     0.76586       epoch run time: 0 min, 4.06 sec\n",
      "2       0.41527     0.76170       epoch run time: 0 min, 4.06 sec\n"
     ]
    }
   ],
   "source": [
    "learner.fit(lr=0.003,num_cycles=2,cycle_mult = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Method 2 - Train Using a General Structured Data Model from StructuredData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/fastai/courses/dl1/StructuredData.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  for var in cat_vars: df[var] = df[var].astype('category')\n",
      "/home/paperspace/fastai/courses/dl1/StructuredData.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  for var in cont_vars: df[var] = df[var].astype('float32')\n"
     ]
    }
   ],
   "source": [
    "# define data object\n",
    "cat_vars = ['userId','movieId']\n",
    "cont_vars = ['rating']\n",
    "output_var = 'rating'\n",
    "output_type = 'cont'\n",
    "bs = 128\n",
    "\n",
    "df = pd.read_csv(PATH + 'ratings.csv')\n",
    "df = df.reindex(columns=['userId','movieId','rating'])\n",
    "users = df['userId'].unique()\n",
    "items = df['movieId'].unique()\n",
    "user_labels = {users[i]:i for i in range(len(users))}\n",
    "item_labels = {items[i]:i for i in range(len(items))}\n",
    "labels = [user_labels,item_labels]\n",
    "train_df, val_df = SplitDataFrameTrainVal(df)\n",
    "\n",
    "xcat_df, xcont_df, y, scaling_values, category_labels = \\\n",
    "ProcessDataFrame(train_df, cat_vars, cont_vars, output_var, scale_cont = 'No', \n",
    "                 category_labels = labels, unknown_category = False)\n",
    "train_ds = StructuredDataset(xcat_df,xcont_df,y,output_type)\n",
    "\n",
    "xcat_df, xcont_df, y, scaling_values, category_labels = \\\n",
    "ProcessDataFrame(val_df, cat_vars, cont_vars, output_var, scale_cont = 'No', \n",
    "                 category_labels = labels, unknown_category = False)\n",
    "val_ds = StructuredDataset(xcat_df,xcont_df,y,output_type)\n",
    "\n",
    "\n",
    "data = StructuredDataObj(train_ds, val_ds, labels, scaling_values,\n",
    "                         bs, num_workers=4, test_ds = None)\n",
    "\n",
    "\n",
    "# define pytorch model\n",
    "fc_layer_sizes = [50,10,1]\n",
    "emb_sizes = 'default'\n",
    "output_range = [0.5,5.0]\n",
    "dropout_levels = (0,0,[0,0.5,0.5])\n",
    "use_bn = True\n",
    "model = StructuredDataNet.from_dataobj(data, fc_layer_sizes, emb_sizes, output_range, dropout_levels, use_bn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# learner object\n",
    "learner = Learner(PATH,data,model,optimizer,loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   train_loss  val_loss    \n",
      "\n",
      "0       0.89963     0.91686       epoch run time: 0 min, 6.49 sec\n",
      "1       0.74073     0.81896       epoch run time: 0 min, 6.22 sec\n",
      "2       0.68890     0.80451       epoch run time: 0 min, 6.25 sec\n"
     ]
    }
   ],
   "source": [
    "learner.fit(lr=0.003,num_cycles=2,cycle_mult = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   train_loss  val_loss    \n",
      "\n",
      "0       0.68689     0.80359       epoch run time: 0 min, 6.17 sec\n",
      "1       0.63907     0.79171       epoch run time: 0 min, 6.44 sec\n",
      "2       0.64052     0.78692       epoch run time: 0 min, 7.48 sec\n",
      "3       0.61415     0.78966       epoch run time: 0 min, 8.73 sec\n"
     ]
    }
   ],
   "source": [
    "learner.fit(lr=0.003,num_cycles=2,base_cycle_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
